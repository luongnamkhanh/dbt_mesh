#!/usr/bin/env python3
"""
Mesh Source Generator for Native dbt Cross-Project References

Downloads upstream manifest and generates a sources.yml file that
exposes public upstream models as sources in the downstream project.

This approach:
1. Downloads upstream manifest from registry
2. Extracts public models with their metadata
3. Generates models/mesh_sources.yml with source definitions
4. Downstream models use {{ source('dbt_up', 'public_orders') }}

Usage:
    python scripts/sync_mesh.py [--local] [--bucket BUCKET] [--env ENV]

For local testing (no S3):
    python scripts/sync_mesh.py --local
"""

import argparse
import json
import os
import shutil
from pathlib import Path
from typing import Any, Dict, List

# Optional boto3 import for S3 mode
try:
    import boto3
    HAS_BOTO3 = True
except ImportError:
    HAS_BOTO3 = False


def sync_local(registry_base: Path, state_dir: Path, project_name: str, env: str) -> Path:
    """Sync manifest from local filesystem registry"""
    source_path = registry_base / project_name / env / "latest" / "manifest.json"

    if not source_path.exists():
        raise FileNotFoundError(
            f"Upstream manifest not found at {source_path}. "
            f"Ensure {project_name} has published its manifest."
        )

    # Create state directory for this project
    project_state_dir = state_dir / project_name
    project_state_dir.mkdir(parents=True, exist_ok=True)

    target_path = project_state_dir / "manifest.json"
    shutil.copy2(source_path, target_path)

    print(f"âœ“ Synced from local registry:")
    print(f"  Source: {source_path}")
    print(f"  Target: {target_path}")

    return target_path


def sync_s3(bucket: str, state_dir: Path, project_name: str, env: str) -> Path:
    """Sync manifest from S3 registry"""
    if not HAS_BOTO3:
        raise ImportError("boto3 required for S3 sync. Install with: pip install boto3")

    s3_client = boto3.client('s3')

    # S3 key for latest manifest
    s3_key = f"registry/{project_name}/{env}/latest/manifest.json"

    # Create state directory for this project
    project_state_dir = state_dir / project_name
    project_state_dir.mkdir(parents=True, exist_ok=True)

    target_path = project_state_dir / "manifest.json"

    # Download from S3
    s3_client.download_file(bucket, s3_key, str(target_path))

    print(f"âœ“ Synced from S3 registry:")
    print(f"  Source: s3://{bucket}/{s3_key}")
    print(f"  Target: {target_path}")

    return target_path


def extract_public_models(manifest: dict) -> List[Dict[str, Any]]:
    """Extract public model metadata from manifest"""
    public_models = []

    for node_id, node in manifest.get("nodes", {}).items():
        if node.get("resource_type") == "model" and node.get("access") == "public":
            public_models.append({
                "unique_id": node_id,
                "name": node.get("name"),
                "schema": node.get("schema"),
                "database": node.get("database"),
                "description": node.get("description", ""),
                "columns": node.get("columns", {}),
                "relation_name": node.get("relation_name"),
            })

    return public_models


def generate_sources_yml(
    project_name: str,
    public_models: List[Dict[str, Any]],
    output_path: Path
):
    """Generate a sources.yml file from upstream public models"""
    if not public_models:
        print("âš  No public models found - skipping sources.yml generation")
        return

    # Use the first model's database/schema as default (they should be consistent)
    default_database = public_models[0].get("database")
    default_schema = public_models[0].get("schema")

    # Build YAML content manually for precise formatting
    lines = [
        "# Auto-generated by sync_mesh.py - DO NOT EDIT MANUALLY",
        f"# Source: {project_name} upstream manifest",
        "",
        "version: 2",
        "",
        "sources:",
        f"  - name: {project_name}",
        f"    description: \"Public models from upstream {project_name} project (mesh source)\"",
    ]

    if default_database:
        lines.append(f"    database: {default_database}")
    if default_schema:
        lines.append(f"    schema: {default_schema}")

    lines.append("    tables:")

    for model in public_models:
        lines.append(f"      - name: {model['name']}")
        if model.get("description"):
            # Escape quotes in description
            desc = model["description"].replace('"', '\\"')
            lines.append(f'        description: "{desc}"')

        # Add column metadata if available
        if model.get("columns"):
            lines.append("        columns:")
            for col_name, col_info in model["columns"].items():
                lines.append(f"          - name: {col_name}")
                if col_info.get("description"):
                    col_desc = col_info["description"].replace('"', '\\"')
                    lines.append(f'            description: "{col_desc}"')

    # Write the file
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w') as f:
        f.write('\n'.join(lines) + '\n')

    print(f"âœ“ Generated sources file: {output_path}")


def main():
    parser = argparse.ArgumentParser(description="Sync upstream manifests and generate mesh sources")
    parser.add_argument("--local", action="store_true", help="Use local filesystem instead of S3")
    parser.add_argument("--bucket", default=os.environ.get("DBT_MESH_BUCKET"), help="S3 bucket name")
    parser.add_argument("--env", default="prod", help="Environment (dev/staging/prod)")
    parser.add_argument("--upstream", default="dbt_up", help="Upstream project name")
    parser.add_argument("--registry-path", default="../registry", help="Local registry base path")

    args = parser.parse_args()

    # Determine paths
    script_dir = Path(__file__).parent
    project_dir = script_dir.parent
    state_dir = project_dir / "state"
    models_dir = project_dir / "models"

    print(f"Syncing upstream manifest: {args.upstream}")

    # Sync manifest
    if args.local:
        registry_base = project_dir / args.registry_path
        manifest_path = sync_local(registry_base, state_dir, args.upstream, args.env)
    else:
        if not args.bucket:
            raise ValueError("S3 bucket required. Set --bucket or DBT_MESH_BUCKET env var")
        manifest_path = sync_s3(args.bucket, state_dir, args.upstream, args.env)

    # Load and process manifest
    with open(manifest_path) as f:
        manifest = json.load(f)

    public_models = extract_public_models(manifest)

    if public_models:
        print(f"\nðŸ“¦ Found {len(public_models)} public model(s):")
        for model in public_models:
            print(f"   - {model['name']} ({model['unique_id']})")
    else:
        print("\nâš  Warning: No public models found in upstream manifest")

    # Generate sources.yml
    sources_path = models_dir / f"_mesh_{args.upstream}.yml"
    generate_sources_yml(args.upstream, public_models, sources_path)

    print(f"\nâœ“ Mesh sync complete!")
    print(f"\nUsage in models:")
    print(f"  SELECT * FROM {{{{ source('{args.upstream}', 'public_orders') }}}}")


if __name__ == "__main__":
    main()
